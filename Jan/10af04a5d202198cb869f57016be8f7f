The fast-growing video app, created by Chinese company ByteDance, was one of the most downloaded apps last year. While there are jokes, clips, memes and videos in which youngsters - some scantily clad - lip-sync and dance to popular music, TikTok also has a quirky side, including the #cerealchallenge. This involves a person lying on their back with their mouth open while someone pours milk and cereal into their mouth and then tries to eat it with a spoon. TikTok also recently partnered with the World Economic Forum to launch the #AllTheDifference challenge to promote inclusion and diversity. But while youngsters share their lives with the world through the social media site, they could easily attract online predators, be exposed to and also create inappropriate content, and have their privacy infringed upon. Although there are no official figures to measure the penetration of TikTok in the country, it appears that South African youngsters are not exempt from this harm as hashtags such as #tiktoksouthafrica and #southafrica indicate that the social media service has a total of 7000 videos and 350000 South African fans. Videos categorised with the hashtag #tiktoksouthafrica already have more than 400 million views. South African expert on social media law at The Digital Law Company, Emma Sadleir, said this week that TikTok, if not properly monitored, could endanger those under the age of 18. “Because TikTok music videos are largely based on pop music, it is rife with music videos which contain highly explicit sexual language. “Even more worrying is the huge amount of content relating to self-harm and suicide which is easily accessible through the app,” she said. Sadleir said an innocent act, specifically of girls, posting videos of themselves dancing could catch the eye of those who have nefarious intentions. “A huge user base of young children dancing to mostly sexually explicit lyrics is an absolutely perfect breeding ground for sexual predators. Her comments were echoed by the BBC which found the app failed to remove online predators who were sending sexual messages to children. Despite the app’s requirement that users be at least 13 years old to use it, and that anyone under the age of 18 must have approval of a parent or guardian, the BBC came across several accounts run by children, some as young as 9 years old. “The account should belong to an adult who can closely monitor the type of content posted,” said Sadleir. She added that all youngster’s accounts should be private urged parents to have talks with their children about “stranger danger”, ensure they are appropriately dressed in the videos, and implement screen-time limits. Saturday Star